{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0193caed-75f1-459c-9621-55e9d4766d6a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Análise Exploratória dos Dados - Ureia\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c6ef0-85fb-4c0d-a530-8eb15ddd1072",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "print(\"Todas as bibliotecas necessárias foram importadas com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85548d2e-9c3e-44c0-9d8d-695bb64fb9fc",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Configs and Paths:\n",
    "---\n",
    "\n",
    "Adicionando todos os caminhos que serão utilizados durante as análises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a506e-0aa2-4287-a885-3d231754ece0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.abspath(\"/lakehouse/default/Files/dados_estruturados\")\n",
    "DATA_DIR = Path(DATA_DIR)\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "\n",
    "paths = {\n",
    "    \"merged\": RAW_DIR / \"merged_data.csv\",\n",
    "    \"pink\": RAW_DIR / \"pink_sheet_monthly.csv\",\n",
    "    \"ptax\": RAW_DIR / \"bcb_ptax_usdbrl_1990-01_2025-12.csv\",\n",
    "    \"gscpi\": RAW_DIR / \"nyfed_gscpi.csv\",\n",
    "    \"oni\": RAW_DIR / \"noaa_oni.csv\",\n",
    "    \"gpr\": RAW_DIR / \"gpr.csv\",\n",
    "    \"events\": RAW_DIR / \"main_events.csv\",\n",
    "    \"trade\": RAW_DIR / \"urea_trade_features.csv\",\n",
    "    \"india\": RAW_DIR / \"india_urea_hs6_by_partner_wits.csv\",\n",
    "}\n",
    "\n",
    "UREA_COL = \"urea_usd\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e9cb3-23b2-4bcf-a589-9d60c20ec5a4",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Métodos auxiliares:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7103ef9-5e3f-47c7-b23d-06028d550e0a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "def to_month_start(dt_series: pd.Series) -> pd.Series:\n",
    "    s = pd.to_datetime(dt_series, errors=\"coerce\")\n",
    "    return s.dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "def add_seasonality(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    m = out.index.month.astype(int)\n",
    "    out[\"month\"] = m\n",
    "    out[\"month_sin\"] = np.sin(2 * np.pi * m / 12)\n",
    "    out[\"month_cos\"] = np.cos(2 * np.pi * m / 12)\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_lags(df: pd.DataFrame, cols: List[str], lags: List[int]) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    new_cols = {}\n",
    "    for c in cols:\n",
    "        if c not in out.columns:\n",
    "            continue\n",
    "        for L in lags:\n",
    "            new_cols[f\"{c}_lag{L}\"] = out[c].shift(L)\n",
    "    if new_cols:\n",
    "        out = pd.concat([out, pd.DataFrame(new_cols)], axis=1)\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_rolling(df: pd.DataFrame, cols: List[str], windows: List[int]) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    new_cols = {}\n",
    "    for c in cols:\n",
    "        if c not in out.columns:\n",
    "            continue\n",
    "        for w in windows:\n",
    "            new_cols[f\"{c}_ma{w}\"] = out[c].rolling(w).mean()\n",
    "    if new_cols:\n",
    "        out = pd.concat([out, pd.DataFrame(new_cols)], axis=1)\n",
    "    return out\n",
    "\n",
    "\n",
    "def lag_correlation_table(df: pd.DataFrame, target: str, features: List[str], lags: List[int]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    y = df[target]\n",
    "    for f in features:\n",
    "        if f not in df.columns:\n",
    "            continue\n",
    "        for L in lags:\n",
    "            corr = y.corr(df[f].shift(L))\n",
    "            rows.append({\"feature\": f, \"lag\": L, \"corr\": corr})\n",
    "    out = pd.DataFrame(rows).dropna()\n",
    "    out[\"abs_corr\"] = out[\"corr\"].abs()\n",
    "    return out.sort_values([\"abs_corr\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "def plot_series(df: pd.DataFrame, cols: List[str], outpath: str, title: str) -> None:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            plt.plot(df.index, df[c], label=c)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_bar(df: pd.DataFrame, x: str, y: str, outpath: str, title: str, top_n: int = 20) -> None:\n",
    "    d = df.head(top_n).copy()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(d[x][::-1], d[y][::-1])\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "\n",
    "def dataset_overview(name: str, df: pd.DataFrame, date_col: str = None):\n",
    "    out = {\n",
    "        \"dataset\": name,\n",
    "        \"rows\": len(df),\n",
    "        \"cols\": df.shape[1],\n",
    "    }\n",
    "    if date_col and date_col in df.columns:\n",
    "        d = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "        out[\"min_date\"] = d.min()\n",
    "        out[\"max_date\"] = d.max()\n",
    "    else:\n",
    "        out[\"min_date\"] = pd.NaT\n",
    "        out[\"max_date\"] = pd.NaT\n",
    "    out[\"missing_cells_pct\"] = round(float(df.isna().mean().mean() * 100), 3)\n",
    "    return out\n",
    "\n",
    "\n",
    "def zscore(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(float)\n",
    "    return (s - s.mean()) / s.std(ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292631a5-0f55-48ce-9b05-70df914997a9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Carregando os datasets:\n",
    "---\n",
    "Atribuindo cada dataset a uma variável para facilitar manipulações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a463c-2409-4cdc-8f85-0d41cbebc47c",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "df_merged = pd.read_csv(paths[\"merged\"])\n",
    "df_merged[\"date\"] = pd.to_datetime(df_merged[\"date\"], errors=\"coerce\")\n",
    "df_merged = df_merged.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "df_pink = pd.read_csv(paths[\"pink\"])\n",
    "df_pink[\"date\"] = pd.to_datetime(df_pink[\"date\"], errors=\"coerce\")\n",
    "\n",
    "df_ptax = pd.read_csv(paths[\"ptax\"])\n",
    "df_ptax[\"date\"] = pd.to_datetime(df_ptax[\"date\"], errors=\"coerce\")\n",
    "\n",
    "df_gscpi = pd.read_csv(paths[\"gscpi\"])\n",
    "df_gscpi[\"date\"] = pd.to_datetime(df_gscpi[\"date\"], errors=\"coerce\")\n",
    "\n",
    "df_oni = pd.read_csv(paths[\"oni\"])\n",
    "df_oni[\"date\"] = pd.to_datetime(df_oni[\"date\"], errors=\"coerce\")\n",
    "\n",
    "df_gpr = pd.read_csv(paths[\"gpr\"])\n",
    "df_gpr[\"date\"] = pd.to_datetime(df_gpr[\"date\"], errors=\"coerce\")\n",
    "\n",
    "df_events = pd.read_csv(paths[\"events\"])\n",
    "df_events[\"date\"] = pd.to_datetime(df_events[\"date\"], errors=\"coerce\")\n",
    "\n",
    "df_trade = pd.read_csv(paths[\"trade\"])\n",
    "df_trade[\"date\"] = pd.to_datetime(df_trade[\"date\"], errors=\"coerce\")\n",
    "mask = df_trade[\"flowDesc\"] == \"Re-import\"\n",
    "df_trade = df_trade[~mask].copy()\n",
    "\n",
    "df_trade_pivoted = df_trade.pivot_table(\n",
    "    index='date',\n",
    "    columns='flowDesc',\n",
    "    values=['CHN_tonnes', 'CHN_value_usd', 'BRA_tonnes', 'BRA_value_usd'],\n",
    "    aggfunc='first'\n",
    ")\n",
    "df_trade_pivoted.columns = ['_'.join(col).strip() for col in df_trade_pivoted.columns.values]\n",
    "\n",
    "df_india = pd.read_csv(paths[\"india\"])\n",
    "df_india[\"date\"] = pd.to_datetime(df_india[\"year\"].astype(str) + \"-01-01\", errors=\"coerce\")\n",
    "\n",
    "df_merged = df_merged.set_index(\"date\")\n",
    "df_merged = df_merged.drop(columns=[\"index\"])\n",
    "\n",
    "if UREA_COL not in df_merged.columns:\n",
    "    raise ValueError(f\"Coluna-alvo não encontrada: {UREA_COL}\")\n",
    "\n",
    "# Adiciona features de comércio internacional ao dataset principal\n",
    "df_merged = df_merged.merge(df_trade_pivoted, left_index=True, right_index=True, how=\"left\")\n",
    "df_merged['urea_brl'] = df_merged[UREA_COL] * df_merged['usdbrl']\n",
    "\n",
    "df_merged.to_csv(RAW_DIR / \"merged_data_with_trade.csv\")\n",
    "\n",
    "\n",
    "# Aplica filtro de data inicial como 1995-01-01.\n",
    "df_merged = df_merged[df_merged.index >= pd.to_datetime(\"1995-01-01\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c021b7b6-8c5f-4582-9b17-adba18179614",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Gerar overview dos datasets:\n",
    "---\n",
    "Permite termos uma noção inicial da sanidade dos dados, verificando sua completude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ec7a6-d648-4da4-b585-6f200887d913",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "overview = pd.DataFrame([\n",
    "    dataset_overview(\"merged_data.csv\", df_merged.reset_index(), \"date\"),\n",
    "    dataset_overview(\"pink_sheet_monthly.csv\", df_pink, \"date\"),\n",
    "    dataset_overview(\"ptax_usdbrl.csv\", df_ptax, \"date\"),\n",
    "    dataset_overview(\"nyfed_gscpi.csv\", df_gscpi, \"date\"),\n",
    "    dataset_overview(\"noaa_oni.csv\", df_oni, \"date\"),\n",
    "    dataset_overview(\"gpr.csv\", df_gpr, \"date\"),\n",
    "    dataset_overview(\"main_events.csv\", df_events, \"date\"),\n",
    "    dataset_overview(\"urea_trade_features.csv\", df_trade, \"date\"),\n",
    "    dataset_overview(\"india_urea_hs6_by_partner_wits.csv\", df_india, \"date\"),\n",
    "])\n",
    "\n",
    "overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b45f1c7-0468-4f12-9539-f03f52473898",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Análise de Entropia\n",
    "---\n",
    "Análise de Entropia para entendermos o quão caótica são as variáveis numéricas que estaremos analisando durante esse estudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2fc832-c11d-4ffb-95da-353908f845aa",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "# Selecionar as features de interesse\n",
    "features = [\"urea_usd\", \"crude_oil_usd\", \"natural_gas_usd\", \"usdbrl\", \"gscpi\", \"gpr\"]\n",
    "df_features = df_merged[features].dropna()\n",
    "\n",
    "# Calcular a entropia para cada feature\n",
    "entropy_results = {}\n",
    "\n",
    "for col in features:\n",
    "    # Normalizar os dados para criar uma distribuição de probabilidade\n",
    "    # Usando histograma para discretizar valores contínuos\n",
    "    hist, bin_edges = np.histogram(df_features[col], bins=30, density=True)\n",
    "    \n",
    "    # Normalizar para soma = 1 (distribuição de probabilidade)\n",
    "    hist = hist / hist.sum()\n",
    "    \n",
    "    # Remover bins vazios para evitar log(0)\n",
    "    hist = hist[hist > 0]\n",
    "    \n",
    "    # Calcular entropia\n",
    "    ent = entropy(hist, base=2)  # base=2 para bits, base=e para nats\n",
    "    entropy_results[col] = ent\n",
    "\n",
    "# Criar DataFrame com resultados\n",
    "entropy_df = pd.DataFrame.from_dict(\n",
    "    entropy_results, \n",
    "    orient='index', \n",
    "    columns=['entropy']\n",
    ").sort_values('entropy', ascending=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ENTROPIA DAS FEATURES (em bits)\")\n",
    "print(\"=\" * 60)\n",
    "print(entropy_df)\n",
    "print(\"\\nInterpretação:\")\n",
    "print(\"- Maior entropia = maior incerteza/variabilidade\")\n",
    "print(\"- Menor entropia = mais previsível/concentrada\")\n",
    "\n",
    "# Visualização\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Gráfico de barras da entropia\n",
    "ax1.barh(entropy_df.index, entropy_df['entropy'], color='steelblue')\n",
    "ax1.set_xlabel('Entropia (bits)', fontsize=11)\n",
    "ax1.set_title('Entropia por Feature\\n(Medida de incerteza/variabilidade)', fontsize=12, fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Distribuições normalizadas para comparação visual\n",
    "for i, col in enumerate(features):\n",
    "    hist, bin_edges = np.histogram(df_features[col], bins=30, density=True)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    ax2.plot(bin_centers, hist / hist.sum(), label=f\"{col} (H={entropy_results[col]:.2f})\", alpha=0.7)\n",
    "\n",
    "ax2.set_xlabel('Valor normalizado', fontsize=10)\n",
    "ax2.set_ylabel('Densidade de probabilidade', fontsize=10)\n",
    "ax2.set_title('Distribuições de Probabilidade das Features', fontsize=12, fontweight='bold')\n",
    "ax2.legend(fontsize=8, loc='best')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64236909-1f34-4e27-8bfe-2ba458adf622",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "# Selecionar as features de interesse\n",
    "features = [\"urea_usd\", \"crude_oil_usd\", \"natural_gas_usd\", \"usdbrl\", \"gscpi\", \"gpr\"]\n",
    "df_features = df_merged[features].dropna()\n",
    "\n",
    "# Calcular o Índice de Shannon (Entropia de Shannon) para cada feature\n",
    "shannon_results = {}\n",
    "\n",
    "for col in features:\n",
    "    # Normalizar os dados para criar uma distribuição de probabilidade\n",
    "    # Usando histograma para discretizar valores contínuos\n",
    "    hist, bin_edges = np.histogram(df_features[col], bins=30, density=True)\n",
    "    \n",
    "    # Normalizar para soma = 1 (distribuição de probabilidade)\n",
    "    hist = hist / hist.sum()\n",
    "    \n",
    "    # Remover bins vazios para evitar log(0)\n",
    "    hist = hist[hist > 0]\n",
    "    \n",
    "    # Calcular Índice de Shannon (entropia em nats - base natural)\n",
    "    shannon_index = entropy(hist, base=np.e)  # base=e para nats (índice de Shannon clássico)\n",
    "    shannon_results[col] = shannon_index\n",
    "\n",
    "# Criar DataFrame com resultados\n",
    "shannon_df = pd.DataFrame.from_dict(\n",
    "    shannon_results, \n",
    "    orient='index', \n",
    "    columns=['shannon_index']\n",
    ").sort_values('shannon_index', ascending=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ÍNDICE DE SHANNON (ENTROPIA DE SHANNON) - em nats\")\n",
    "print(\"=\" * 70)\n",
    "print(shannon_df)\n",
    "print(\"\\nInterpretação do Índice de Shannon:\")\n",
    "print(\"- Maior valor = maior diversidade/incerteza na distribuição\")\n",
    "print(\"- Menor valor = maior concentração/previsibilidade\")\n",
    "print(\"- Unidade: nats (logaritmo natural)\")\n",
    "print(\"- Conversão: 1 nat ≈ 1.443 bits\")\n",
    "\n",
    "# Adicionar versão em bits para comparação\n",
    "shannon_df['shannon_bits'] = shannon_df['shannon_index'] / np.log(2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ÍNDICE DE SHANNON - Comparação (nats vs bits)\")\n",
    "print(\"=\" * 70)\n",
    "print(shannon_df)\n",
    "\n",
    "# Visualização\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Gráfico de barras horizontal - Índice de Shannon (nats)\n",
    "ax1.barh(shannon_df.index, shannon_df['shannon_index'], color='steelblue', alpha=0.8)\n",
    "ax1.set_xlabel('Índice de Shannon (nats)', fontsize=11)\n",
    "ax1.set_title('Índice de Shannon por Feature\\n(Medida de diversidade/entropia)', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 2. Gráfico de barras horizontal - Índice de Shannon (bits)\n",
    "ax2.barh(shannon_df.index, shannon_df['shannon_bits'], color='coral', alpha=0.8)\n",
    "ax2.set_xlabel('Índice de Shannon (bits)', fontsize=11)\n",
    "ax2.set_title('Índice de Shannon por Feature\\n(Convertido para bits)', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 3. Distribuições de probabilidade (densidade)\n",
    "for i, col in enumerate(features):\n",
    "    hist, bin_edges = np.histogram(df_features[col], bins=30, density=True)\n",
    "    hist_prob = hist / hist.sum()\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    \n",
    "    ax3.plot(bin_centers, hist_prob, \n",
    "             label=f\"{col}\\n(H={shannon_results[col]:.3f} nats)\", \n",
    "             alpha=0.7, linewidth=2)\n",
    "\n",
    "ax3.set_xlabel('Valor (normalizado)', fontsize=10)\n",
    "ax3.set_ylabel('Densidade de probabilidade', fontsize=10)\n",
    "ax3.set_title('Distribuições de Probabilidade das Features\\n(base para cálculo do Índice de Shannon)', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax3.legend(fontsize=8, loc='best')\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# 4. Comparação visual: nats vs bits\n",
    "x_pos = np.arange(len(shannon_df))\n",
    "width = 0.35\n",
    "\n",
    "ax4.bar(x_pos - width/2, shannon_df['shannon_index'], width, \n",
    "        label='Shannon (nats)', color='steelblue', alpha=0.8)\n",
    "ax4.bar(x_pos + width/2, shannon_df['shannon_bits'], width, \n",
    "        label='Shannon (bits)', color='coral', alpha=0.8)\n",
    "\n",
    "ax4.set_xlabel('Features', fontsize=11)\n",
    "ax4.set_ylabel('Índice de Shannon', fontsize=11)\n",
    "ax4.set_title('Comparação: Índice de Shannon em nats vs bits', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(shannon_df.index, rotation=45, ha='right')\n",
    "ax4.legend(fontsize=10)\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análise estatística adicional\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ANÁLISE COMPARATIVA - ÍNDICE DE SHANNON\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nFeature mais diversa (maior entropia):\")\n",
    "print(f\"  → {shannon_df.index[0]}: {shannon_df.iloc[0]['shannon_index']:.4f} nats\")\n",
    "print(f\"\\nFeature mais concentrada (menor entropia):\")\n",
    "print(f\"  → {shannon_df.index[-1]}: {shannon_df.iloc[-1]['shannon_index']:.4f} nats\")\n",
    "print(f\"\\nRazão max/min: {shannon_df.iloc[0]['shannon_index'] / shannon_df.iloc[-1]['shannon_index']:.2f}x\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a51a6-c7fd-479f-a6b3-c8092649008a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Cobertura temporal por dataset:\n",
    "---\n",
    "Deixar explícito quais fontes cobrem quais períodos, verificando se existe sobreposição suficiente para análises conjuntas. É um slide ótimo para justificar por que alguns modelos/insights só fazem sentido a partir de certo ano (por exemplo, se um índice começa muito depois)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499620b-7e0f-4902-b84e-b153cb96ec90",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 4.8))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "timeline = overview.dropna(subset=[\"min_date\", \"max_date\"]).copy()\n",
    "timeline = timeline.sort_values(\"min_date\")\n",
    "y = np.arange(len(timeline))\n",
    "ax.hlines(y=y, xmin=timeline[\"min_date\"], xmax=timeline[\"max_date\"], label=\"Janela temporal\", color=\"darkblue\")\n",
    "ax.plot(timeline[\"min_date\"], y, marker=\"o\", linestyle=\"None\", label=\"Início\")\n",
    "ax.plot(timeline[\"max_date\"], y, marker=\"o\", linestyle=\"None\", label=\"Fim\")\n",
    "ax.vlines(pd.Timestamp(\"1994-01-01\"), ymin=0, ymax=len(timeline)-1, color=\"red\", linestyle=\"--\", label=\"Janela temporal de análise\")\n",
    "ax.set_yticks(y)\n",
    "ax.set_yticklabels(timeline[\"dataset\"])\n",
    "ax.set_title(\"Cobertura temporal por dataset (início e fim)\")\n",
    "ax.set_xlabel(\"Data\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441da536-eb1d-4136-97de-bcd9dd6dfe36",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Mapa de dados faltantes:\n",
    "---\n",
    "Serve para enxergar rapidamente se os faltantes estão concentrados em determinados períodos (ex.: início da série) ou em variáveis específicas. Ajuda em decisões como recorte temporal para a análise, escolha de imputação, ou até a exclusão de variáveis pouco confiáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1d535-aa18-4158-b772-9ac1c011aeb9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = df_merged.select_dtypes(include=[np.number]).columns.tolist()\n",
    "heat = df_merged[num_cols].isna().astype(int).to_numpy().T\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5.2))\n",
    "im = ax.imshow(heat, aspect=\"auto\", interpolation=\"nearest\", cmap=\"binary\", vmin=0, vmax=1)\n",
    "ax.set_title(\"Mapa de dados faltantes (0 = presente, 1 = ausente) - variáveis numéricas\")\n",
    "ax.set_yticks(np.arange(len(num_cols)))\n",
    "ax.set_yticklabels(num_cols, fontsize=7)\n",
    "\n",
    "dates = df_merged.index.to_numpy()\n",
    "if len(dates) > 0:\n",
    "    years = pd.DatetimeIndex(dates).year\n",
    "    tick_idx = np.where((pd.DatetimeIndex(dates).month == 1))[0]\n",
    "    ax.set_xticks(tick_idx[::2] if len(tick_idx) > 25 else tick_idx)\n",
    "    ax.set_xticklabels(pd.DatetimeIndex(dates)[ax.get_xticks()].year, rotation=90, fontsize=7)\n",
    "\n",
    "cbar = fig.colorbar(im, ax=ax, fraction=0.02, pad=0.02, ticks=[0, 1])\n",
    "cbar.set_label(\"Dado Faltante\", rotation=270, labelpad=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59e500-a7c3-485e-aa75-30df3ce7c7f0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Análise de Preço x Tempo (USD e BRL)\n",
    "---\n",
    "Verificando como fica a evolução do preço da ureia ao longo dos anos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41febaf8-2f4e-4ae1-9675-12f2a3211528",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "feature1 = UREA_COL\n",
    "feature2 = 'urea_brl'\n",
    "\n",
    "tmp_df = df_merged[df_merged.index >= pd.to_datetime(\"1995-01-01\")].copy()\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, figsize=(12, 8))\n",
    "if feature1 in tmp_df.columns:\n",
    "    ax1.plot(tmp_df.index, tmp_df[feature1], color='C0', label=feature1)\n",
    "    ax1.plot(tmp_df.index, tmp_df[feature1].rolling(12, min_periods=6).mean().values, color='gray', label=\"Média móvel 12m\", alpha=0.7)\n",
    "    ax1.set_ylabel(feature1)\n",
    "    ax1.legend(loc='upper left')\n",
    "if feature2 in tmp_df.columns:\n",
    "    ax2.plot(tmp_df.index, tmp_df[feature2], color='C1', label=feature2)\n",
    "    ax2.plot(tmp_df.index, tmp_df[feature2].rolling(12, min_periods=6).mean().values, color='gray', label=\"Média móvel 12m\", alpha=0.7)\n",
    "    ax2.set_ylabel(feature2)\n",
    "    ax2.legend(loc='upper left')\n",
    "if feature1 in tmp_df.columns and feature2 in tmp_df.columns:\n",
    "    ax3.plot(tmp_df.index, tmp_df[feature1], color='C0', label=feature1)\n",
    "    ax3.plot(tmp_df.index, tmp_df[feature2], color='C1', label=feature2)\n",
    "    ax3.legend(loc='upper left')\n",
    "    ax3.set_ylabel('preço/t')\n",
    "\n",
    "    years = pd.date_range(tmp_df.index.values.min(), tmp_df.index.values.max(), freq=\"YS\")\n",
    "    ax3.set_xticks(years)\n",
    "    ax3.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "    ax3.tick_params(axis=\"x\", rotation=60)\n",
    "\n",
    "ax2.set_xlabel('Date')\n",
    "fig.suptitle(f'Ureia em dólares e em reais ao longo do tempo (30 anos)', fontsize=16)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.99])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f208fd3-b641-48f6-b5c9-a16676fd31b1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "feature1 = 'urea_usd'\n",
    "feature2 = 'urea_brl'\n",
    "\n",
    "tmp_df = df_merged[df_merged.index >= pd.to_datetime(\"1995-01-01\")].copy()\n",
    "\n",
    "# Normalizar com z-score\n",
    "tmp_df['urea_usd_norm'] = (tmp_df[feature1] - tmp_df[feature1].mean()) / tmp_df[feature1].std()\n",
    "tmp_df['urea_brl_norm'] = (tmp_df[feature2] - tmp_df[feature2].mean()) / tmp_df[feature2].std()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12, 8))\n",
    "\n",
    "# Gráfico 1: Séries normalizadas\n",
    "ax1.plot(tmp_df.index, tmp_df['urea_usd_norm'], color='C0', label='urea_usd (normalizado)', linewidth=2)\n",
    "ax1.plot(tmp_df.index, tmp_df['urea_brl_norm'], color='C1', label='urea_brl (normalizado)', linewidth=2)\n",
    "ax1.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax1.set_ylabel('Z-score')\n",
    "ax1.set_title('Ureia USD vs BRL - Séries Normalizadas (Z-score)')\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico 2: Escala original (para referência)\n",
    "ax2_right = ax2.twinx()\n",
    "ax2.plot(tmp_df.index, tmp_df[feature1], color='C0', label='urea_usd', linewidth=2)\n",
    "ax2_right.plot(tmp_df.index, tmp_df[feature2], color='C1', label='urea_brl', linewidth=2)\n",
    "ax2.set_ylabel('US$/t', color='C0')\n",
    "ax2_right.set_ylabel('R$/t', color='C1')\n",
    "ax2.tick_params(axis='y', labelcolor='C0')\n",
    "ax2_right.tick_params(axis='y', labelcolor='C1')\n",
    "ax2.set_title('Ureia USD vs BRL - Escala Original')\n",
    "ax2.legend(loc='upper left', fontsize=8)\n",
    "ax2_right.legend(loc='upper right', fontsize=8)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "years = pd.date_range(tmp_df.index.values.min(), tmp_df.index.values.max(), freq=\"YS\")\n",
    "ax2.set_xticks(years)\n",
    "ax2.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "ax2.tick_params(axis=\"x\", rotation=60)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f56ac2-9d78-4e6c-9e06-b358a7547ee0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Variação Mensal:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9653f11-5821-47ad-948d-dd5ed2d731ea",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(tmp_df.index, tmp_df[feature1].pct_change() * 100, color='C0', label='urea_usd (% change)', linewidth=1.5, alpha=0.8)\n",
    "ax.plot(tmp_df.index, tmp_df[feature2].pct_change() * 100, color='C1', label='urea_brl (% change)', linewidth=1.5, alpha=0.8)\n",
    "ax.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_ylabel('Variação (%)')\n",
    "ax.set_title('Ureia USD vs BRL - Variação Mensal (%)')\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15405dbc-6b4b-4c30-a9b8-d4adf8dd40fe",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "s_urea = df_merged[UREA_COL].astype(float)\n",
    "\n",
    "ret = s_urea.pct_change() * 100\n",
    "vol12 = ret.rolling(12, min_periods=6).std()\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4.2))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(ret.index, ret.values, label=\"Variação % mensal\")\n",
    "ax.plot(vol12.index, vol12.values, label=\"Volatilidade 12m (desvio-padrão)\")\n",
    "ax.set_title(\"Ureia (USD) - variação percentual mensal x volatilidade móvel\")\n",
    "ax.set_ylabel(\"%\")\n",
    "ax.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a915ab-01dc-494b-be42-4d64c3644f80",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Análises de Boxplot:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd367e02-94b6-4b8a-81e4-57c64e52f02e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "s_urea = s_urea[s_urea.index >= pd.to_datetime(\"1995-01-01\")]\n",
    "\n",
    "tmp = pd.DataFrame({\"date\": s_urea.index, \"urea\": s_urea.values})\n",
    "tmp[\"month\"] = tmp[\"date\"].dt.month\n",
    "data_by_month = [tmp.loc[tmp[\"month\"] == m, \"urea\"].dropna().values for m in range(1, 13)]\n",
    "\n",
    "fig = plt.figure(figsize=(10.8, 4.2))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.boxplot(data_by_month, labels=[str(m) for m in range(1, 13)], showfliers=False)\n",
    "ax.set_title(\"Boxplot - distribuição do preço da Ureia por mês (30 anos - 1995 a 2025)\")\n",
    "ax.set_xlabel(\"Mês\")\n",
    "ax.set_ylabel(\"US$/t\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c428ce-80f0-4a0c-942e-2a2a880b3e9d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame({\"date\": s_urea.index, \"urea\": s_urea.values})\n",
    "tmp[\"month\"] = tmp[\"date\"].dt.month\n",
    "tmp[\"year\"] = tmp[\"date\"].dt.year\n",
    "tmp[\"year_group\"] = (tmp[\"year\"] // 10) * 10\n",
    "\n",
    "year_groups = sorted(tmp[\"year_group\"].unique())\n",
    "year_labels = [f\"{yr}-{yr+9}\" if yr + 9 <= tmp[\"year\"].max() else f\"{yr}-{tmp['year'].max()}\" for yr in year_groups]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "# Posições para os boxplots (mês, depois período)\n",
    "positions = []\n",
    "data_to_plot = []\n",
    "colors_list = []\n",
    "month_to_positions = {m: [] for m in range(1, 13)}  # Mapear mês para posições\n",
    "pos = 1\n",
    "\n",
    "color_palette = ['lightblue', 'lightgreen', 'lightpink']\n",
    "\n",
    "for month in range(1, 13):\n",
    "    for idx, year_group in enumerate(year_groups):\n",
    "        data = tmp.loc[(tmp[\"year_group\"] == year_group) & (tmp[\"month\"] == month), \"urea\"].dropna().values\n",
    "        if len(data) > 0:\n",
    "            data_to_plot.append(data)\n",
    "            positions.append(pos)\n",
    "            colors_list.append(color_palette[idx % len(color_palette)])\n",
    "            month_to_positions[month].append(pos)  # Guardar posição para este mês\n",
    "            pos += 1\n",
    "    pos += 1  # Espaço entre meses\n",
    "\n",
    "bp = ax.boxplot(data_to_plot, positions=positions, widths=0.6, patch_artist=True, showfliers=False)\n",
    "\n",
    "# Colorir os boxplots\n",
    "for patch, color in zip(bp['boxes'], colors_list):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Adicionar labels para os meses\n",
    "month_positions = []\n",
    "month_labels = []\n",
    "for month in range(1, 13):\n",
    "    if month_to_positions[month]:  # Se há dados para este mês\n",
    "        avg_pos = np.mean(month_to_positions[month])\n",
    "        month_positions.append(avg_pos)\n",
    "        month_labels.append(str(month))\n",
    "\n",
    "ax.set_xticks(month_positions)\n",
    "ax.set_xticklabels(month_labels)\n",
    "ax.set_ylabel(\"US$/t\")\n",
    "ax.set_title(\"Boxplot - Distribuição do preço da Ureia por mês e período de 10 anos\", fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Legenda com cores para períodos\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=color_palette[i % len(color_palette)], label=year_labels[i]) \n",
    "                   for i in range(len(year_groups))]\n",
    "ax.legend(handles=legend_elements, loc='upper left', title='Período', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad83051-e9f5-4b8a-8493-c16eb6480f79",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Análise STL (Season-Trend with LOESS):\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d153c8a-cdd3-4a7f-aada-0c7d1b4a054b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "stl_series = s_urea.dropna()\n",
    "stl = STL(stl_series, period=12, robust=True).fit()\n",
    "\n",
    "translations = {\n",
    "    \"trend\": \"tendência\",\n",
    "    \"seasonal\": \"sazonalidade\",\n",
    "    \"resid\": \"residual\",\n",
    "}\n",
    "\n",
    "for comp_name, comp_series in [\n",
    "    (\"trend\", stl.trend),\n",
    "    (\"seasonal\", stl.seasonal),\n",
    "    (\"resid\", stl.resid),\n",
    "]:\n",
    "    fig, ax = plt.subplots(figsize=(12, 4.0))\n",
    "    ax.plot(comp_series.index, comp_series.values, linewidth=1.5)\n",
    "    ax.set_title(f\"Decomposição STL - componente: {translations[comp_name]}\", fontsize=13, fontweight='bold')\n",
    "    ax.set_ylabel(\"US$/t\", fontsize=11)\n",
    "    ax.set_xlabel(\"Ano\", fontsize=11)\n",
    "    \n",
    "    # Configurar anos no eixo X\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    \n",
    "    # Rotação e alinhamento\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right', fontsize=9)\n",
    "    \n",
    "    # Grid para melhor leitura\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0aff4-6c9e-4f7a-a760-08572453bce5",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "seasonal = stl.seasonal\n",
    "\n",
    "data_corte = seasonal.index.max() - pd.DateOffset(years=5)\n",
    "seasonal_recent = seasonal[seasonal.index > data_corte]\n",
    "monthly_avg = seasonal_recent.groupby(seasonal_recent.index.month).mean()\n",
    "\n",
    "# Criar nomes dos meses para o eixo X\n",
    "month_names = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', \n",
    "               'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']\n",
    "\n",
    "# Plotar o Gráfico de Barras\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Criar cores condicionais: Verde para preço baixo (compra), Vermelho para preço alto\n",
    "colors = ['green' if x < 0 else 'red' for x in monthly_avg.values]\n",
    "\n",
    "bars = ax.bar(month_names, monthly_avg.values, color=colors, alpha=0.7, edgecolor='black')\n",
    "\n",
    "# Estilização\n",
    "ax.set_title(\"Sazonalidade média mensal (últimos 5 anos)\", fontsize=14)\n",
    "ax.set_ylabel(\"Impacto no Preço (US$/t)\", fontsize=12)\n",
    "ax.set_xlabel(\"Mês\", fontsize=12)\n",
    "ax.axhline(0, color='black', linewidth=1, linestyle='-') # Linha zero\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Adicionar o valor exato em cima/baixo das barras\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    offset = 2 if height > 0 else -2 \n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + offset,\n",
    "            f'{height:.1f}',\n",
    "            ha='center', va='bottom' if height > 0 else 'top', \n",
    "            fontsize=10, fontweight='bold', color='black')\n",
    "\n",
    "ax.set_ylim(-60, 60)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70116c33-0ae3-4f4c-9bc2-1464e066d8e8",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Correlações:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ef4a8-9fa3-4578-a73d-a46b4eb4d51b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.tsa.stattools import ccf\n",
    "\n",
    "# ============================================================================\n",
    "# 1. HEATMAP DE CORRELAÇÃO - NÍVEIS\n",
    "# ============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"1. MATRIZ DE CORRELAÇÃO - NÍVEIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "key_vars = ['urea_usd', 'natural_gas_usd', 'crude_oil_usd', 'usdbrl',\n",
    "            'gscpi', 'oni', 'gpr', 'dap_usd', 'potassium_usd', 'maize_usd', 'wheat_usd', 'soybeans_usd']\n",
    "key_vars = [v for v in key_vars if v in df_merged.columns]\n",
    "\n",
    "corr_levels = df_merged[key_vars].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(corr_levels, annot=True, fmt='.3f', cmap='RdYlGn', center=0,\n",
    "            vmin=-1, vmax=1, square=True, linewidths=0.5, \n",
    "            cbar_kws={\"shrink\": 0.8}, ax=ax)\n",
    "ax.set_title('Matriz de Correlação - Níveis (Pearson)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 2. HEATMAP DE CORRELAÇÃO - VARIAÇÕES MOM (%)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2. MATRIZ DE CORRELAÇÃO - VARIAÇÕES MOM (%)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_mom = df_merged[key_vars].pct_change() * 100\n",
    "df_mom.columns = [f\"{c}_mom\" for c in df_mom.columns]\n",
    "corr_mom = df_mom.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(corr_mom, annot=True, fmt='.3f', cmap='RdYlGn', center=0,\n",
    "            vmin=-1, vmax=1, square=True, linewidths=0.5,\n",
    "            cbar_kws={\"shrink\": 0.8}, ax=ax)\n",
    "ax.set_title('Matriz de Correlação - Variações MoM (%)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 3. HEATMAP DE CORRELAÇÃO - VARIAÇÕES YOY (%)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3. MATRIZ DE CORRELAÇÃO - VARIAÇÕES YOY (%)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_yoy = df_merged[key_vars].pct_change(12) * 100\n",
    "df_yoy.columns = [f\"{c}_yoy\" for c in df_yoy.columns]\n",
    "corr_yoy = df_yoy.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(corr_yoy, annot=True, fmt='.3f', cmap='RdYlGn', center=0,\n",
    "            vmin=-1, vmax=1, square=True, linewidths=0.5,\n",
    "            cbar_kws={\"shrink\": 0.8}, ax=ax)\n",
    "ax.set_title('Matriz de Correlação - Variações YoY (%)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 4. SCATTER PLOTS COM LINHA DE TENDÊNCIA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4. SCATTER PLOTS - UREIA vs VARIÁVEIS CHAVE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "scatter_vars = ['natural_gas_usd', 'crude_oil_usd', 'usdbrl', 'gscpi']\n",
    "scatter_vars = [v for v in scatter_vars if v in df_merged.columns]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, var in enumerate(scatter_vars):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Dados válidos\n",
    "    data = df_merged[['urea_usd', var]].dropna()\n",
    "    x = data[var].values\n",
    "    y = data['urea_usd'].values\n",
    "    \n",
    "    # Scatter\n",
    "    ax.scatter(x, y, alpha=0.5, s=20, edgecolors='k', linewidths=0.5)\n",
    "    \n",
    "    # Linha de tendência\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_line = np.linspace(x.min(), x.max(), 100)\n",
    "    ax.plot(x_line, p(x_line), \"r--\", linewidth=2, label=f'y={z[0]:.2f}x+{z[1]:.2f}')\n",
    "    \n",
    "    # Correlação\n",
    "    corr, pval = pearsonr(x, y)\n",
    "    \n",
    "    ax.set_xlabel(translations.get(var, var), fontsize=11)\n",
    "    ax.set_ylabel('Ureia (US$/t)', fontsize=11)\n",
    "    ax.set_title(f'Ureia vs {translations.get(var, var)}\\nCorr={corr:.3f}, p={pval:.4f}',\n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 5. SCATTER POR REGIME (PRÉ/PÓS EVENTOS IMPORTANTES)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5. SCATTER POR REGIME TEMPORAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Definir regimes baseados em eventos importantes\n",
    "regimes = {\n",
    "    'Pre-COVID (< 2020)': df_merged.index < pd.Timestamp('2020-01-01'),\n",
    "    'COVID (2020-2021)': (df_merged.index >= pd.Timestamp('2020-01-01')) & \n",
    "                         (df_merged.index < pd.Timestamp('2022-01-01')),\n",
    "    'Guerra Ucrânia (2022+)': df_merged.index >= pd.Timestamp('2022-01-01')\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Ureia vs Gás Natural\n",
    "ax = axes[0]\n",
    "colors = ['blue', 'orange', 'red']\n",
    "for idx, (regime_name, mask) in enumerate(regimes.items()):\n",
    "    data = df_merged.loc[mask, ['urea_usd', 'natural_gas_usd']].dropna()\n",
    "    if len(data) > 0:\n",
    "        ax.scatter(data['natural_gas_usd'], data['urea_usd'], \n",
    "                  alpha=0.6, s=30, label=regime_name, color=colors[idx])\n",
    "\n",
    "ax.set_xlabel('Gás Natural (US$/MMBtu)', fontsize=11)\n",
    "ax.set_ylabel('Ureia (US$/t)', fontsize=11)\n",
    "ax.set_title('Ureia vs Gás Natural - Por Regime', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Ureia vs USD/BRL\n",
    "ax = axes[1]\n",
    "for idx, (regime_name, mask) in enumerate(regimes.items()):\n",
    "    data = df_merged.loc[mask, ['urea_usd', 'usdbrl']].dropna()\n",
    "    if len(data) > 0:\n",
    "        ax.scatter(data['usdbrl'], data['urea_usd'], \n",
    "                  alpha=0.6, s=30, label=regime_name, color=colors[idx])\n",
    "\n",
    "ax.set_xlabel('USD/BRL', fontsize=11)\n",
    "ax.set_ylabel('Ureia (US$/t)', fontsize=11)\n",
    "ax.set_title('Ureia vs Câmbio - Por Regime', fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 6. CROSS-CORRELATION FUNCTION (CCF)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"6. CROSS-CORRELATION FUNCTION (CCF)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "ccf_vars = ['natural_gas_usd', 'crude_oil_usd', 'usdbrl', 'gscpi']\n",
    "ccf_vars = [v for v in ccf_vars if v in df_merged.columns]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "max_lag = 12\n",
    "\n",
    "for idx, var in enumerate(ccf_vars):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Dados válidos\n",
    "    data = df_merged[['urea_usd', var]].dropna()\n",
    "    y = data['urea_usd'].values\n",
    "    x = data[var].values\n",
    "    \n",
    "    # Calcular CCF\n",
    "    ccf_values = ccf(y, x, adjusted=False)[:max_lag+1]\n",
    "    lags = np.arange(0, max_lag+1)\n",
    "    \n",
    "    # Plot\n",
    "    ax.stem(lags, ccf_values, basefmt=' ')\n",
    "    ax.axhline(0, color='k', linestyle='-', linewidth=0.8)\n",
    "    ax.axhline(1.96/np.sqrt(len(y)), color='r', linestyle='--', linewidth=1, \n",
    "               label='95% CI')\n",
    "    ax.axhline(-1.96/np.sqrt(len(y)), color='r', linestyle='--', linewidth=1)\n",
    "    \n",
    "    ax.set_xlabel('Lag (meses)', fontsize=11)\n",
    "    ax.set_ylabel('Correlação', fontsize=11)\n",
    "    ax.set_title(f'CCF: Ureia vs {translations.get(var, var)}', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='best', fontsize=9)\n",
    "    ax.set_xlim(-0.5, max_lag+0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# 7. LEAD-LAG PLOTS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"7. LEAD-LAG ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "lead_lag_vars = ['natural_gas_usd', 'crude_oil_usd']\n",
    "max_leads = 6\n",
    "\n",
    "for var in lead_lag_vars:\n",
    "    if var not in df_merged.columns:\n",
    "        continue\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for lag in range(1, max_leads+1):\n",
    "        ax = axes[lag-1]\n",
    "        \n",
    "        # Criar dados com lag\n",
    "        df_lag = df_merged[['urea_usd', var]].copy()\n",
    "        df_lag[f'{var}_lag{lag}'] = df_lag[var].shift(lag)\n",
    "        df_lag = df_lag.dropna()\n",
    "        \n",
    "        x = df_lag[f'{var}_lag{lag}'].values\n",
    "        y = df_lag['urea_usd'].values\n",
    "        \n",
    "        # Scatter\n",
    "        ax.scatter(x, y, alpha=0.5, s=20, edgecolors='k', linewidths=0.5)\n",
    "        \n",
    "        # Linha de tendência\n",
    "        z = np.polyfit(x, y, 1)\n",
    "        p = np.poly1d(z)\n",
    "        x_line = np.linspace(x.min(), x.max(), 100)\n",
    "        ax.plot(x_line, p(x_line), \"r--\", linewidth=2)\n",
    "        \n",
    "        # Correlação\n",
    "        corr, pval = pearsonr(x, y)\n",
    "        \n",
    "        ax.set_xlabel(f'{translations.get(var, var)} (t-{lag})', fontsize=10)\n",
    "        ax.set_ylabel('Ureia (t)', fontsize=10)\n",
    "        ax.set_title(f'Lag {lag}: Corr={corr:.3f}, p={pval:.4f}',\n",
    "                     fontsize=11, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    fig.suptitle(f'Lead-Lag Analysis: {translations.get(var, var)} → Ureia',\n",
    "                 fontsize=14, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c39ed3-c6f5-4220-b1e3-8a0b441f125f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Correlações Defasadas:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4480c746-bf6b-40a3-83aa-9c8187f1f618",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def lagged_corr(target: pd.Series, feature: pd.Series, max_lag: int = 24):\n",
    "    # corr(target_t, feature_{t-lag}) for lag in [-max_lag, +max_lag]\n",
    "    lags = np.arange(-max_lag, max_lag + 1)\n",
    "    out = []\n",
    "    for lag in lags:\n",
    "        shifted = feature.shift(lag)\n",
    "        d = pd.concat([target, shifted], axis=1).dropna()\n",
    "        out.append(d.iloc[:, 0].corr(d.iloc[:, 1]) if len(d) > 5 else np.nan)\n",
    "    return pd.Series(out, index=lags, name=\"corr\")\n",
    "\n",
    "translations = {\n",
    "    \"natural_gas_usd\": \"Gás Natural (US$/MMBtu)\",\n",
    "    \"crude_oil_usd\": \"Petróleo Bruto (US$/bbl)\",\n",
    "    \"usdbrl\": \"Taxa de Câmbio USD/BRL\",\n",
    "    \"gscpi\": \"Global Supply Chain Pressure Index (GSCPI)\",\n",
    "    \"oni\": \"Oceanic Niño Index (ONI)\",\n",
    "    \"gpr\": \"Índice de Risco Geopolítico Global (GPR)\",\n",
    "}\n",
    "\n",
    "lag_features = [\"natural_gas_usd\", \"crude_oil_usd\", \"usdbrl\", \"gscpi\", \"oni\", \"gpr\"]\n",
    "lag_summ = []\n",
    "\n",
    "for feat in lag_features:\n",
    "    if feat not in df_merged.columns:\n",
    "        continue\n",
    "    lc = lagged_corr(s_urea, df_merged[feat].astype(float), max_lag=18)\n",
    "    best_lag = int(lc.abs().idxmax()) if lc.dropna().size else np.nan\n",
    "    best_corr = float(lc.loc[best_lag]) if not np.isnan(best_lag) else np.nan\n",
    "    lag_summ.append({\"feature\": feat, \"best_lag_months\": best_lag, \"corr_at_best_lag\": best_corr})\n",
    "\n",
    "    fig = plt.figure(figsize=(10.5, 4.0))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(lc.index, lc.values)\n",
    "    ax.axhline(0, linewidth=1, color=\"gray\", linestyle=\"--\")\n",
    "    ax.set_title(f\"Correlação defasada: Ureia vs {translations.get(feat, feat)} (lag em meses)\")\n",
    "    ax.set_xlabel(\"Lag (meses). Positivo = feature atrasada; Negativo = feature adiantada\")\n",
    "    ax.set_ylabel(\"Correlação\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0fe50b-7202-484e-a88e-e78664c83873",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "def rolling_corr(a: pd.Series, b: pd.Series, window: int = 12):\n",
    "    d = pd.concat([a, b], axis=1).dropna()\n",
    "    return d.iloc[:, 0].rolling(window).corr(d.iloc[:, 1])\n",
    "\n",
    "for feat in [\"natural_gas_usd\", \"crude_oil_usd\", \"usdbrl\", \"gscpi\"]:\n",
    "    if feat not in df_merged.columns:\n",
    "        continue\n",
    "    rc = rolling_corr(s_urea, df_merged[feat].astype(float), window=24)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 4.0))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(rc.index, rc.values)\n",
    "    ax.axhline(0, linewidth=1)\n",
    "    ax.set_title(f\"Correlação móvel (24m): Ureia vs {feat}\")\n",
    "    ax.set_ylabel(\"Correlação\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b7c311-d8ab-4f29-9c19-4ea29156a4ff",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "events = df_events.dropna(subset=[\"date\", \"event\"]).copy()\n",
    "events = events.sort_values(\"date\")\n",
    "\n",
    "# Compute event-month return\n",
    "event_impact = []\n",
    "for _, row in events.iterrows():\n",
    "    d = row[\"date\"]\n",
    "    if d not in df_merged.index:\n",
    "        continue\n",
    "    \n",
    "    # Usar .iloc[0] para pegar o primeiro valor se houver duplicatas\n",
    "    if d in ret.index:\n",
    "        ret_val = ret.loc[d]\n",
    "        r = float(ret_val.iloc[0]) if isinstance(ret_val, pd.Series) else float(ret_val)\n",
    "    else:\n",
    "        r = np.nan\n",
    "    \n",
    "    if d in s_urea.index:\n",
    "        price_val = s_urea.loc[d]\n",
    "        p = float(price_val.iloc[0]) if isinstance(price_val, pd.Series) else float(price_val)\n",
    "    else:\n",
    "        p = np.nan\n",
    "    \n",
    "    event_impact.append({\"date\": d, \"event\": row[\"event\"], \"urea_usd_mt\": p, \"urea_mom_pct\": r})\n",
    "\n",
    "event_impact_df = pd.DataFrame(event_impact).sort_values(\"date\")\n",
    "\n",
    "# Plot with markers for events\n",
    "fig = plt.figure(figsize=(12, 4.5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(s_urea.index, s_urea.values, label=\"urea_usd\", linewidth=1.5)\n",
    "\n",
    "# Obter valores de ureia para as datas dos eventos\n",
    "ev_dates = event_impact_df[\"date\"].values\n",
    "ev_vals = event_impact_df[\"urea_usd_mt\"].values\n",
    "\n",
    "# Plotar marcadores apenas onde existem valores válidos\n",
    "valid_mask = ~np.isnan(ev_vals)\n",
    "ax.scatter(ev_dates[valid_mask], ev_vals[valid_mask], \n",
    "           label=\"Eventos históricos\", s=50, color='red', \n",
    "           marker='o', zorder=5, alpha=0.7)\n",
    "\n",
    "ax.set_title(\"Ureia com marcação de meses com eventos históricos (main_events)\", \n",
    "             fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel(\"US$/t\", fontsize=11)\n",
    "ax.set_xlabel(\"Data\", fontsize=11)\n",
    "ax.legend(loc=\"best\", fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce125dd-5bed-4be2-8e22-1db913e5f19e",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dependencies": {
   "lakehouse": {
    "default_lakehouse": "3849dea4-acde-48c0-be50-52bae6e0fb92",
    "default_lakehouse_name": "lh_analytics_bronze",
    "default_lakehouse_workspace_id": "1b15bf20-01dc-470c-9cff-3e53d32a3ef2",
    "known_lakehouses": [
     {
      "id": "3849dea4-acde-48c0-be50-52bae6e0fb92"
     }
    ]
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

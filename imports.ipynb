{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2394dad3",
   "metadata": {},
   "source": [
    "### A. **Preço da ureia + commodities correlatas (base central)**\n",
    "\n",
    "* **World Bank – Commodity Price Data (“Pink Sheet”)**: traz série **mensal** de preços de commodities, incluindo **fertilizantes (ureia)** e também **gás natural, petróleo, grãos, outros fertilizantes**, etc. Ótima para montar features consistentes e alinhadas em frequência.\n",
    "* (Alternativa) **IMF Primary Commodity Prices**: também tem fertilizantes e séries de referência.\n",
    "\n",
    "**Por que é “a base”**: com ela você já cobre direto vários itens da lista do cliente: gás, petróleo, grãos, nitrogenados substitutos e até proxies de energia.\n",
    "\n",
    "---\n",
    "\n",
    "### B. **Câmbio (para preço local e efeito de importação)**\n",
    "\n",
    "* **BCB PTAX (API OData)**: cotações diárias (compra/venda) e você agrega para mensal (média/último dia útil).\n",
    "\n",
    "---\n",
    "\n",
    "### C. **Fretes / logística (proxy robusta e mensal)**\n",
    "\n",
    "* **NY Fed – Global Supply Chain Pressure Index (GSCPI)**: índice mensal que incorpora custos de transporte (inclui medidas baseadas em frete marítimo como BDI/Harpex) e variáveis de oferta. Serve como proxy muito boa para “frete marítimo / gargalos”.\n",
    "\n",
    "---\n",
    "\n",
    "### D. **Geopolítica (guerras, sanções, tensões, tarifas)**\n",
    "\n",
    "* **Geopolitical Risk Index (GPR)** (Caldara & Iacoviello): série **mensal** amplamente usada como proxy quantitativa de risco geopolítico (guerras/tensão/sanções).\n",
    "* (Opcional) **Economic Policy Uncertainty (EPU)** via FRED para “política / tarifas / incerteza macro” (também mensal).\n",
    "\n",
    "---\n",
    "\n",
    "### E. **Clima (chuvas / ENSO como proxy global)**\n",
    "\n",
    "* **NOAA ONI (Oceanic Niño Index)**: série mensal em CSV (ENSO), boa proxy de variações climáticas com impacto em agricultura/demanda logística.\n",
    "---\n",
    "\n",
    "### F. **Trade flows (China exportação, Índia import/tenders) – opcional**\n",
    "\n",
    "* **UN Comtrade / WITS**: dá para extrair exportações/importações de ureia (ex.: China) e usar como feature (volume/valor), mas automatização pode exigir mais “engenharia”.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2d8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from io import BytesIO\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e694dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Config / utilitários\n",
    "# =========================\n",
    "\n",
    "WORLD_BANK_PINK_SHEET_MONTHLY_XLSX = (\n",
    "    \"https://thedocs.worldbank.org/en/doc/5d903e848db1d1b83e0ec8f744e55570-0350012021/related/CMO-Historical-Data-Monthly.xlsx\"\n",
    ")\n",
    "\n",
    "NYFED_GSCPI_XLSX = (\n",
    "    \"https://www.newyorkfed.org/medialibrary/research/interactives/gscpi/downloads/gscpi_data.xlsx\"\n",
    ")\n",
    "\n",
    "NOAA_ONI_CSV = \"https://psl.noaa.gov/data/correlation/oni.csv\"\n",
    "\n",
    "GPR_XLSX = \"https://www.matteoiacoviello.com/gpr_files/gpr_web_latest.xlsx\"\n",
    "\n",
    "# BCB PTAX (OData) – exemplo comum com parâmetros:\n",
    "# https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/odata/CotacaoDolarPeriodo(dataInicial=@dataInicial,dataFinalCotacao=@dataFinalCotacao)?@dataInicial='01-01-2020'&@dataFinalCotacao='12-31-2050'&$format=json&$select=cotacaoCompra,cotacaoVenda,dataHoraCotacao\n",
    "BCB_PTAX_BASE = \"https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/odata\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SeriesSpec:\n",
    "    out_name: str\n",
    "    patterns: List[str]  # regex list to find a column in Pink Sheet\n",
    "\n",
    "\n",
    "# Tentei deixar genérico o suficiente para sobreviver a pequenas mudanças de header.\n",
    "PINK_SHEET_SERIES: List[SeriesSpec] = [\n",
    "    SeriesSpec(\"urea_usd\", [r\"\\burea\\b\"]),\n",
    "    SeriesSpec(\"natural_gas_usd\", [r\"natural\\s*gas\", r\"\\bng\\b\"]),\n",
    "    SeriesSpec(\"crude_oil_usd\", [r\"crude.*oil\", r\"\\bbrent\\b\", r\"\\bwt[i|l]\\b\"]),\n",
    "    SeriesSpec(\"maize_usd\", [r\"\\bmaize\\b\", r\"\\bcorn\\b\"]),\n",
    "    SeriesSpec(\"wheat_usd\", [r\"\\bwheat\\b\"]),\n",
    "    SeriesSpec(\"soybeans_usd\", [r\"\\bsoy\\b\", r\"\\bsoybeans?\\b\"]),\n",
    "    SeriesSpec(\"ammonia_usd\", [r\"\\bammonia\\b\"]),\n",
    "    SeriesSpec(\"dap_usd\", [r\"\\bdap\\b\", r\"diammonium\\s*phosphate\"]),\n",
    "    SeriesSpec(\"potassium_usd\", [r\"\\bpotassium\\b\"]),\n",
    "]\n",
    "\n",
    "\n",
    "def _safe_mkdir(path: str) -> None:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def _http_get(url: str, timeout: int = 60) -> bytes:\n",
    "    r = requests.get(url, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    return r.content\n",
    "\n",
    "\n",
    "def _to_month_start(dt: pd.Series) -> pd.Series:\n",
    "    d = pd.to_datetime(dt, errors=\"coerce\")\n",
    "    return d.dt.to_period(\"M\").dt.to_timestamp(how=\"start\")\n",
    "\n",
    "\n",
    "def _month_index(df: pd.DataFrame, date_col: str = \"date\") -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[date_col] = _to_month_start(df[date_col])\n",
    "    df = df.dropna(subset=[date_col])\n",
    "    return df.set_index(date_col).sort_index()\n",
    "\n",
    "\n",
    "def _pick_best_column(columns: List[str], patterns: List[str]) -> Optional[str]:\n",
    "    cols_norm = {c: re.sub(r\"\\s+\", \" \", str(c)).strip().lower() for c in columns}\n",
    "    for pat in patterns:\n",
    "        rx = re.compile(pat, flags=re.IGNORECASE)\n",
    "        matches = [c for c, cn in cols_norm.items() if rx.search(cn)]\n",
    "        if len(matches) == 1:\n",
    "            return matches[0]\n",
    "        if len(matches) > 1:\n",
    "            # Heurística: se tiver \"urea\" e \"gulf\"/\"bulk\"/\"granular\", etc, escolha o mais descritivo\n",
    "            # Caso não, escolha o primeiro em ordem alfabética (estável).\n",
    "            matches_sorted = sorted(matches, key=lambda x: (len(str(x)), str(x)))\n",
    "            return matches_sorted[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Loaders\n",
    "# =========================\n",
    "\n",
    "def load_pink_sheet_monthly(selected: List[SeriesSpec]) -> pd.DataFrame:\n",
    "    content = _http_get(WORLD_BANK_PINK_SHEET_MONTHLY_XLSX)\n",
    "    xls = pd.ExcelFile(BytesIO(content))\n",
    "\n",
    "    # Normalmente o primeiro sheet já é o \"Monthly Prices\", mas deixamos robusto:\n",
    "    sheet_name = xls.sheet_names[1]\n",
    "    df_raw = pd.read_excel(xls, sheet_name=sheet_name, engine=\"openpyxl\", skiprows=4, header=[0, 1])\n",
    "\n",
    "    # Flatten MultiIndex columns: juntar nome e unidade com espaço\n",
    "    df_raw.columns = [' '.join(col).strip() for col in df_raw.columns.values]\n",
    "\n",
    "    # Descobrir coluna de data (alguns arquivos usam \"Date\" / \"Month\" / \"Time\")\n",
    "    possible_date_cols = [c for c in df_raw.columns if str(c).strip().lower() in (\"date\", \"time\", \"month\")]\n",
    "    if not possible_date_cols:\n",
    "        # fallback: primeira coluna\n",
    "        date_col = df_raw.columns[0]\n",
    "    else:\n",
    "        date_col = possible_date_cols[0]\n",
    "\n",
    "    df = df_raw.rename(columns={date_col: \"Date\"}).copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"].str.replace('M', ''), format='%Y%m', errors='coerce')\n",
    "\n",
    "    # Selecionar séries por regex\n",
    "    picked = {}\n",
    "    missing = []\n",
    "    for spec in selected:\n",
    "        col = _pick_best_column(list(df.columns), spec.patterns)\n",
    "        if col is None:\n",
    "            missing.append(spec.out_name)\n",
    "            continue\n",
    "        picked[spec.out_name] = col\n",
    "\n",
    "    if missing:\n",
    "        print(\"[AVISO] Algumas séries não foram encontradas no Pink Sheet:\", missing)\n",
    "        # Ajuda a ajustar rapidamente:\n",
    "        print(\"[DEBUG] Colunas disponíveis (amostra):\", list(df.columns)[:30])\n",
    "\n",
    "    out = df[[\"date\"] + list(picked.values())].rename(columns=picked)\n",
    "\n",
    "    # Converter tudo para numérico (algumas colunas podem vir como object)\n",
    "    for c in out.columns:\n",
    "        if c != \"date\":\n",
    "            out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "\n",
    "    return _month_index(out, \"date\")\n",
    "\n",
    "\n",
    "def load_bcb_ptax_usdbrl(date_start: str, date_end: str) -> pd.DataFrame:\n",
    "    # A API usa formato dd-mm-aaaa nas strings do parâmetro\n",
    "    # Vamos aceitar start/end como \"YYYY-MM\" ou \"YYYY-MM-DD\" e converter.\n",
    "    start_dt = pd.to_datetime(date_start) if len(date_start) > 7 else pd.to_datetime(date_start + \"-01\")\n",
    "    end_dt = pd.to_datetime(date_end) if len(date_end) > 7 else (pd.to_datetime(date_end + \"-01\") + pd.offsets.MonthEnd(0))\n",
    "\n",
    "    start_str = start_dt.strftime(\"%m-%d-%Y\")  # muitos exemplos aceitam MM-DD-YYYY\n",
    "    end_str = end_dt.strftime(\"%m-%d-%Y\")\n",
    "\n",
    "    url = (\n",
    "        f\"{BCB_PTAX_BASE}/CotacaoDolarPeriodo(dataInicial=@dataInicial,dataFinalCotacao=@dataFinalCotacao)\"\n",
    "        f\"?@dataInicial='{start_str}'&@dataFinalCotacao='{end_str}'&$format=json\"\n",
    "        f\"&$select=cotacaoCompra,cotacaoVenda,dataHoraCotacao\"\n",
    "    )\n",
    "\n",
    "    data = _http_get(url)\n",
    "    j = requests.utils.json.loads(data.decode(\"utf-8\"))\n",
    "    values = j.get(\"value\", [])\n",
    "    df = pd.DataFrame(values)\n",
    "    if df.empty:\n",
    "        raise RuntimeError(\"BCB PTAX: retorno vazio. Verifique janela de datas/URL.\")\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"dataHoraCotacao\"], errors=\"coerce\")\n",
    "    df[\"usdbrl\"] = pd.to_numeric(df[\"cotacaoVenda\"], errors=\"coerce\")\n",
    "\n",
    "    # Agregar para mensal (média)\n",
    "    df_m = (\n",
    "        df.dropna(subset=[\"date\", \"usdbrl\"])\n",
    "          .assign(date=_to_month_start(df[\"date\"]))\n",
    "          .groupby(\"date\", as_index=False)[\"usdbrl\"]\n",
    "          .mean()\n",
    "    )\n",
    "    return _month_index(df_m, \"date\")\n",
    "\n",
    "\n",
    "def load_nyfed_gscpi() -> pd.DataFrame:\n",
    "    content = _http_get(NYFED_GSCPI_XLSX)\n",
    "    xls = pd.ExcelFile(BytesIO(content))\n",
    "    # Em geral há um sheet com a série e coluna \"GSCPI\"\n",
    "    sheet = xls.sheet_names[0]\n",
    "    df = pd.read_excel(xls, sheet_name=sheet, engine=\"openpyxl\")\n",
    "\n",
    "    # Tentar inferir colunas:\n",
    "    date_col = _pick_best_column(list(df.columns), [r\"date\", r\"month\", r\"time\"]) or df.columns[0]\n",
    "    val_col = _pick_best_column(list(df.columns), [r\"gscpi\"]) or df.columns[1]\n",
    "\n",
    "    out = df.rename(columns={date_col: \"date\", val_col: \"gscpi\"})[[\"date\", \"gscpi\"]].copy()\n",
    "    out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n",
    "    out[\"gscpi\"] = pd.to_numeric(out[\"gscpi\"], errors=\"coerce\")\n",
    "    return _month_index(out, \"date\")\n",
    "\n",
    "\n",
    "def load_noaa_oni() -> pd.DataFrame:\n",
    "    content = _http_get(NOAA_ONI_CSV)\n",
    "    df = pd.read_csv(BytesIO(content))\n",
    "    # Esperado: Date, ONI\n",
    "    date_col = _pick_best_column(list(df.columns), [r\"date\"]) or df.columns[0]\n",
    "    val_col = _pick_best_column(list(df.columns), [r\"oni\"]) or df.columns[1]\n",
    "    out = df.rename(columns={date_col: \"date\", val_col: \"oni\"})[[\"date\", \"oni\"]].copy()\n",
    "    out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n",
    "    out[\"oni\"] = pd.to_numeric(out[\"oni\"], errors=\"coerce\")\n",
    "    return _month_index(out, \"date\")\n",
    "\n",
    "\n",
    "def load_gpr() -> pd.DataFrame:\n",
    "    content = _http_get(GPR_XLSX)\n",
    "    xls = pd.ExcelFile(BytesIO(content))\n",
    "    sheet = xls.sheet_names[0]\n",
    "    df = pd.read_excel(xls, sheet_name=sheet, engine=\"openpyxl\")\n",
    "\n",
    "    # Procura coluna de data e índice principal\n",
    "    date_col = _pick_best_column(list(df.columns), [r\"date\", r\"month\", r\"time\"]) or df.columns[0]\n",
    "    gpr_col = _pick_best_column(list(df.columns), [r\"(^|\\s)gpr(\\s|$)\"])  # \"GPR\"\n",
    "    if gpr_col is None:\n",
    "        # fallback: primeira coluna numérica depois da data\n",
    "        cand = [c for c in df.columns if c != date_col]\n",
    "        gpr_col = cand[0]\n",
    "\n",
    "    out = df.rename(columns={date_col: \"date\", gpr_col: \"gpr\"})[[\"date\", \"gpr\"]].copy()\n",
    "    out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n",
    "    out[\"gpr\"] = pd.to_numeric(out[\"gpr\"], errors=\"coerce\")\n",
    "    return _month_index(out, \"date\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Feature engineering / EDA\n",
    "# =========================\n",
    "\n",
    "def add_seasonality(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    m = out.index.month.astype(int)\n",
    "    out[\"month\"] = m\n",
    "    out[\"month_sin\"] = np.sin(2 * np.pi * m / 12)\n",
    "    out[\"month_cos\"] = np.cos(2 * np.pi * m / 12)\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_lags(df: pd.DataFrame, cols: List[str], lags: List[int]) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        if c not in out.columns:\n",
    "            continue\n",
    "        for L in lags:\n",
    "            out[f\"{c}_lag{L}\"] = out[c].shift(L)\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_rolling(df: pd.DataFrame, cols: List[str], windows: List[int]) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        if c not in out.columns:\n",
    "            continue\n",
    "        for w in windows:\n",
    "            out[f\"{c}_ma{w}\"] = out[c].rolling(w).mean()\n",
    "    return out\n",
    "\n",
    "\n",
    "def lag_correlation_table(df: pd.DataFrame, target: str, features: List[str], lags: List[int]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    y = df[target]\n",
    "    for f in features:\n",
    "        if f not in df.columns:\n",
    "            continue\n",
    "        for L in lags:\n",
    "            corr = y.corr(df[f].shift(L))\n",
    "            rows.append({\"feature\": f, \"lag\": L, \"corr\": corr})\n",
    "    out = pd.DataFrame(rows).dropna()\n",
    "    out[\"abs_corr\"] = out[\"corr\"].abs()\n",
    "    return out.sort_values([\"abs_corr\"], ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def train_feature_importance_ts(\n",
    "    df: pd.DataFrame,\n",
    "    target: str,\n",
    "    drop_cols: Optional[List[str]] = None,\n",
    "    n_splits: int = 5,\n",
    "    random_state: int = 42,\n",
    ") -> Tuple[pd.DataFrame, Dict[str, float]]:\n",
    "    drop_cols = drop_cols or []\n",
    "    data = df.dropna(subset=[target]).copy()\n",
    "    X = data.drop(columns=[target] + drop_cols, errors=\"ignore\")\n",
    "    y = data[target].copy()\n",
    "\n",
    "    # Remover colunas não-numéricas\n",
    "    X = X.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "    # Tirar linhas com NA após lags/rolling\n",
    "    mask = X.notna().all(axis=1) & y.notna()\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    fold_metrics = {\"mae\": [], \"rmse\": [], \"r2\": []}\n",
    "\n",
    "    # Modelo simples e interpretável via importâncias + permutação\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=600,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # Avaliação em folds e treino final no full (para importâncias)\n",
    "    for tr, te in tscv.split(X):\n",
    "        Xtr, Xte = X.iloc[tr], X.iloc[te]\n",
    "        ytr, yte = y.iloc[tr], y.iloc[te]\n",
    "        model.fit(Xtr, ytr)\n",
    "        pred = model.predict(Xte)\n",
    "        fold_metrics[\"mae\"].append(mean_absolute_error(yte, pred))\n",
    "        fold_metrics[\"rmse\"].append(np.sqrt(mean_squared_error(yte, pred)))\n",
    "        fold_metrics[\"r2\"].append(r2_score(yte, pred))\n",
    "\n",
    "    metrics_summary = {\n",
    "        \"mae_mean\": float(np.mean(fold_metrics[\"mae\"])),\n",
    "        \"rmse_mean\": float(np.mean(fold_metrics[\"rmse\"])),\n",
    "        \"r2_mean\": float(np.mean(fold_metrics[\"r2\"])),\n",
    "        \"n_obs\": int(len(X)),\n",
    "        \"n_features\": int(X.shape[1]),\n",
    "    }\n",
    "\n",
    "    # Treino final para importâncias\n",
    "    model.fit(X, y)\n",
    "\n",
    "    imp_rf = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "    perm = permutation_importance(model, X, y, n_repeats=15, random_state=random_state, n_jobs=-1)\n",
    "    imp_perm = pd.Series(perm.importances_mean, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"feature\": X.columns,\n",
    "        \"rf_importance\": imp_rf.reindex(X.columns).values,\n",
    "        \"perm_importance\": imp_perm.reindex(X.columns).values,\n",
    "    }).sort_values([\"perm_importance\", \"rf_importance\"], ascending=False)\n",
    "\n",
    "    return out.reset_index(drop=True), metrics_summary\n",
    "\n",
    "\n",
    "def plot_series(df: pd.DataFrame, cols: List[str], outpath: str, title: str) -> None:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            plt.plot(df.index, df[c], label=c)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=140)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_bar(df: pd.DataFrame, x: str, y: str, outpath: str, title: str, top_n: int = 20) -> None:\n",
    "    d = df.head(top_n).copy()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(d[x][::-1], d[y][::-1])\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=140)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b30e0e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = os.path.abspath(\"output\")\n",
    "START_DATE = \"2000-01\"\n",
    "END_DATE = \"2025-12\"\n",
    "TARGET = \"urea_usd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2100cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando Pink Sheet (World Bank)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AVISO] Algumas séries não foram encontradas no Pink Sheet: ['ammonia_usd', 'potash_usd']\n",
      "[DEBUG] Colunas disponíveis (amostra): ['Date', 'Crude oil, average ($/bbl)', 'Crude oil, Brent ($/bbl)', 'Crude oil, Dubai ($/bbl)', 'Crude oil, WTI ($/bbl)', 'Coal, Australian ($/mt)', 'Coal, South African ** ($/mt)', 'Natural gas, US ($/mmbtu)', 'Natural gas, Europe ($/mmbtu)', 'Liquefied natural gas, Japan ($/mmbtu)', 'Natural gas index (2010=100)', 'Cocoa ($/kg)', 'Coffee, Arabica ($/kg)', 'Coffee, Robusta ($/kg)', 'Tea, avg 3 auctions ($/kg)', 'Tea, Colombo ($/kg)', 'Tea, Kolkata ($/kg)', 'Tea, Mombasa ($/kg)', 'Coconut oil ($/mt)', 'Groundnuts ($/mt)', 'Fish meal ($/mt)', 'Groundnut oil ** ($/mt)', 'Palm oil ($/mt)', 'Palm kernel oil ($/mt)', 'Soybeans ($/mt)', 'Soybean oil ($/mt)', 'Soybean meal ($/mt)', 'Rapeseed oil ($/mt)', 'Sunflower oil ($/mt)', 'Barley ($/mt)']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['date'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 1) Loaders\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBaixando Pink Sheet (World Bank)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df_prices = \u001b[43mload_pink_sheet_monthly\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPINK_SHEET_SERIES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBaixando câmbio PTAX (BCB)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m df_fx = load_bcb_ptax_usdbrl(START_DATE, END_DATE)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 120\u001b[39m, in \u001b[36mload_pink_sheet_monthly\u001b[39m\u001b[34m(selected)\u001b[39m\n\u001b[32m    117\u001b[39m     \u001b[38;5;66;03m# Ajuda a ajustar rapidamente:\u001b[39;00m\n\u001b[32m    118\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[DEBUG] Colunas disponíveis (amostra):\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(df.columns)[:\u001b[32m30\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m out = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpicked\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m.rename(columns=picked)\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# Converter tudo para numérico (algumas colunas podem vir como object)\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m out.columns:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EdmarJunyorBevilaqua\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\urea-pricing-analysis-J3cGB9Pi-py3.12\\Lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EdmarJunyorBevilaqua\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\urea-pricing-analysis-J3cGB9Pi-py3.12\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EdmarJunyorBevilaqua\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\urea-pricing-analysis-J3cGB9Pi-py3.12\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['date'] not in index\""
     ]
    }
   ],
   "source": [
    "_safe_mkdir(OUTDIR)\n",
    "figdir = os.path.join(OUTDIR, \"figures\")\n",
    "_safe_mkdir(figdir)\n",
    "\n",
    "# 1) Loaders\n",
    "print(\"Baixando Pink Sheet (World Bank)...\")\n",
    "df_prices = load_pink_sheet_monthly(PINK_SHEET_SERIES)\n",
    "\n",
    "print(\"Baixando câmbio PTAX (BCB)...\")\n",
    "df_fx = load_bcb_ptax_usdbrl(START_DATE, END_DATE)\n",
    "\n",
    "print(\"Baixando GSCPI (NY Fed)...\")\n",
    "df_gscpi = load_nyfed_gscpi()\n",
    "\n",
    "print(\"Baixando GPR (Geopolitical Risk)...\")\n",
    "df_gpr = load_gpr()\n",
    "\n",
    "print(\"Baixando ONI (NOAA)...\")\n",
    "df_oni = load_noaa_oni()\n",
    "\n",
    "# 2) Merge mensal\n",
    "df = df_prices.join(df_fx, how=\"outer\").join(df_gscpi, how=\"outer\").join(df_gpr, how=\"outer\").join(df_oni, how=\"outer\")\n",
    "df = df.loc[(df.index >= pd.to_datetime(START_DATE + \"-01\" if len(START_DATE) == 7 else START_DATE)) &\n",
    "            (df.index <= pd.to_datetime(END_DATE + \"-01\" if len(END_DATE) == 7 else END_DATE) + pd.offsets.MonthEnd(0))]\n",
    "\n",
    "# Exemplo: preço de ureia em BRL como feature/target alternativo\n",
    "if \"urea_usd\" in df.columns and \"usdbrl\" in df.columns:\n",
    "    df[\"urea_brl\"] = df[\"urea_usd\"] * df[\"usdbrl\"]\n",
    "\n",
    "# 3) Feature engineering\n",
    "df = add_seasonality(df)\n",
    "\n",
    "base_features = [c for c in df.columns if c not in {TARGET}]\n",
    "base_features = [c for c in base_features if pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "df = add_lags(df, cols=base_features, lags=[1, 2, 3, 6, 12])\n",
    "df = add_rolling(df, cols=base_features, windows=[3, 6, 12])\n",
    "\n",
    "# 4) EDA: correlação com lags (tabela)\n",
    "feature_cols = [c for c in df.columns if c not in {TARGET}]\n",
    "lag_table = lag_correlation_table(df, target=TARGET, features=feature_cols, lags=[0, 1, 2, 3, 6, 12])\n",
    "lag_table.to_csv(os.path.join(OUTDIR, \"top_correlacoes.csv\"), index=False)\n",
    "\n",
    "# 5) Modelo simples p/ ranking de importância (TimeSeriesSplit)\n",
    "importance_df, metrics = train_feature_importance_ts(\n",
    "    df=df,\n",
    "    target=TARGET,\n",
    "    drop_cols=[],\n",
    "    n_splits=5,\n",
    ")\n",
    "importance_df.to_csv(os.path.join(OUTDIR, \"feature_importance.csv\"), index=False)\n",
    "\n",
    "# 6) Salvar dataset final\n",
    "df_out = df.reset_index().rename(columns={\"index\": \"date\"})\n",
    "df_out.to_csv(os.path.join(OUTDIR, \"dataset_mensal.csv\"), index=False)\n",
    "\n",
    "# 7) Gráficos principais\n",
    "plot_series(df, cols=[TARGET], outpath=os.path.join(figdir, \"01_target.png\"), title=f\"Target: {TARGET}\")\n",
    "\n",
    "plot_series(\n",
    "    df,\n",
    "    cols=[c for c in [\"natural_gas_usd\", \"crude_oil_usd\", \"maize_usd\", \"wheat_usd\", \"usdbrl\", \"gscpi\", \"gpr\", \"oni\"] if c in df.columns],\n",
    "    outpath=os.path.join(figdir, \"02_principais_drivers.png\"),\n",
    "    title=\"Drivers (nível) – seleção\",\n",
    ")\n",
    "\n",
    "plot_bar(\n",
    "    importance_df,\n",
    "    x=\"feature\",\n",
    "    y=\"perm_importance\",\n",
    "    outpath=os.path.join(figdir, \"03_importancia_permutacao.png\"),\n",
    "    title=\"Importância (Permutation Importance) – Top 20\",\n",
    "    top_n=20,\n",
    ")\n",
    "\n",
    "# 8) Log de métricas\n",
    "with open(os.path.join(OUTDIR, \"metrics.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    for k, v in metrics.items():\n",
    "        f.write(f\"{k}: {v}\\n\")\n",
    "\n",
    "print(\"\\nOK! Saídas em:\", OUTDIR)\n",
    "print(\"Métricas (CV):\", metrics)\n",
    "print(\"Dica: se quiser prever preço futuro, você pode trocar o target para 'urea_brl' e/ou criar target shift(-h).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9dd01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urea-pricing-analysis-J3cGB9Pi-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
